#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ONNX å¯è§†åŒ–æ¼”ç¤ºæœåŠ¡ (Windows)

åŠŸèƒ½:
- æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ¨¡å‹å’Œæµ‹è¯•å›¾ç‰‡
- æä¾› REST API è¿›è¡Œæ¨ç†
- æ”¯æŒ YOLOv5 å’Œ YOLOv11 æ¨¡å‹è‡ªåŠ¨è¯†åˆ«
- å‰ç«¯å¯è§†åŒ–å±•ç¤º

ä½¿ç”¨æ–¹æ³•:
    ç›´æ¥è¿è¡Œ: python onnx_demo_serverå‰¯æœ¬.py
    é…ç½®åœ¨ä¸‹æ–¹ CONFIG éƒ¨åˆ†ä¿®æ”¹
"""

import os
import sys
import base64
import time
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from io import BytesIO

import cv2
import numpy as np
import onnxruntime as ort
from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS

# ============================================================
# â˜…â˜…â˜… é…ç½®åŒºåŸŸ - åœ¨æ­¤å¤„ä¿®æ”¹é…ç½® â˜…â˜…â˜…
# ============================================================

# æœåŠ¡é…ç½®
SERVER_HOST = '0.0.0.0'  # ç›‘å¬åœ°å€ï¼Œ0.0.0.0 è¡¨ç¤ºæ‰€æœ‰ç½‘å¡
SERVER_PORT = 8082  # æœåŠ¡ç«¯å£

# ç›®å½•é…ç½®
MODEL_DIR = './'  # ONNX æ¨¡å‹ç›®å½•ï¼ˆå½“å‰ç›®å½•ï¼‰
IMAGE_DIR = './test_images'  # æµ‹è¯•å›¾ç‰‡ç›®å½•

# æ£€æµ‹å‚æ•°é»˜è®¤å€¼
DEFAULT_CONF = 0.25  # é»˜è®¤ç½®ä¿¡åº¦é˜ˆå€¼
DEFAULT_IOU = 0.45  # é»˜è®¤ IOU é˜ˆå€¼

# ============================================================

# ç®—æ³•é…ç½® (ä¸ NPU æœåŠ¡ä¿æŒä¸€è‡´)
ALGO_CONFIG = {
    1: {"name": "æ¾çº¿è™«å®³è¯†åˆ«", "classes": {0: "æ­»äº¡", 1: "é‡åº¦æ‚£ç—…", 2: "è½»åº¦æ‚£ç—…"}},
    2: {"name": "æ²³é“æ·¤ç§¯è¯†åˆ«", "classes": {0: "æ°´æ±¡æŸ“", 1: "æ¼‚æµ®ç¢ç‰‡", 2: "åºŸå¼ƒèˆ¹åª", 3: "æ¸”ä¸šå’Œæ°´äº§å…»æ®–", 4: "åƒåœ¾"}},
    3: {"name": "æ¼‚æµ®ç‰©è¯†åˆ«",
        "classes": {0: "ç“¶å­", 1: "è‰", 2: "æ ‘æ", 3: "ç‰›å¥¶ç›’", 4: "å¡‘æ–™è¢‹", 5: "å¡‘æ–™åƒåœ¾è¢‹", 6: "çƒ", 7: "å¶å­"}},
    4: {"name": "æ¸¸æ³³æ¶‰æ°´è¯†åˆ«",
        "classes": {0: "å¿½ç•¥", 1: "æ¸¸æ³³è€…", 2: "èˆ¹", 3: "æ°´ä¸Šæ‘©æ‰˜è‰‡", 4: "æ•‘ç”Ÿè®¾å¤‡", 5: "æµ®æ ‡"}},
    5: {"name": "è½¦ç‰Œè¯†åˆ«", "classes": {0: "è½¦ç‰Œ"}},
    6: {"name": "äº¤é€šæ‹¥å µè¯†åˆ«", "classes": {0: "è½¦è¾†"}},
    7: {"name": "è·¯é¢ç ´æŸè¯†åˆ«",
        "classes": {0: "é¾Ÿè£‚", 1: "çºµå‘è£‚ç¼", 2: "çºµå‘ä¿®è¡¥å—", 3: "æ£€æŸ¥äº•äº•ç›–", 4: "å‘æ´", 5: "æ¨ªå‘è£‚ç¼",
                    6: "æ¨ªå‘ä¿®è¡¥å—"}},
    8: {"name": "è·¯é¢æ±¡æŸ“",
        "classes": {0: "è£‚ç¼", 1: "ç§¯æ°´", 2: "è·¯é¢æ¾æ•£", 3: "æ³¥æ³é“è·¯", 4: "è·¯è¾¹åƒåœ¾", 5: "å‘æ´"}},
    9: {"name": "äººç¾¤èšé›†è¯†åˆ«", "classes": {0: "è½¦", 1: "äºº"}},
    10: {"name": "éæ³•å‚é’“è¯†åˆ«", "classes": {0: "æ°´è¾¹é’“é±¼", 1: "æ¸¸æ³³æººæ°´", 2: "é’“é±¼ä¼", 3: "èˆ¹"}},
    11: {"name": "æ–½å·¥è¯†åˆ«", "classes": {0: "èµ·é‡æœº", 1: "æŒ–æ˜æœº", 2: "æ‹–æ‹‰æœº", 3: "å¡è½¦"}},
    12: {"name": "ç§¸ç§†ç„šçƒ§", "classes": {0: "ç§¸ç§†å †"}},
    13: {"name": "å˜åŒ–æ£€æµ‹", "classes": {0: "æ— å˜åŒ–", 1: "å˜åŒ–åŒºåŸŸ"}},
    14: {"name": "å é“ç»è¥è¯†åˆ«", "classes": {0: "å é“ç»è¥"}},
    15: {"name": "åƒåœ¾å †æ”¾è¯†åˆ«",
         "classes": {0: "é•¿æ¤…", 1: "å•†ä¸šåƒåœ¾", 2: "éæ³•å€¾å€’ç‚¹", 3: "ç»¿åœ°", 4: "å­”æ´", 5: "æ³½è¥¿æŠ¤æ ", 6: "åœ°å—",
                     7: "åŸææ–™", 8: "ç”Ÿæ´»åƒåœ¾"}},
    16: {"name": "è£¸åœŸæœªè¦†ç›–è¯†åˆ«", "classes": {0: "åƒåœ¾", 1: "è£¸åœŸ"}},
    17: {"name": "å»ºæ§åŒºè¿å»ºè¯†åˆ«", "classes": {0: "è“è‰²å¤©ç¯·", 1: "å…¶ä»–è¿å»º", 2: "æ”¹è£…ç»¿è‰²å°å±‹"}},
    18: {"name": "çƒŸç«è¯†åˆ«", "classes": {0: "çƒŸé›¾", 1: "ç«"}},
    19: {"name": "å…‰ä¼æ¿ç¼ºé™·æ£€æµ‹", "classes": {0: "æœ‰ç¼ºé™·çš„å…‰ä¼ç”µæ± "}},
    20: {"name": "å›­åŒºå¤œé—´å…¥ä¾µæ£€æµ‹", "classes": {0: "äºº", 1: "è½¦", 2: "è‡ªè¡Œè½¦"}},
    21: {"name": "å›­åŒºå¤–ç«‹é¢ç—…å®³è¯†åˆ«",
         "classes": {0: "å¢™ä½“è…èš€", 1: "å¢™ä½“å¼€è£‚", 2: "å¢™ä½“åŠ£åŒ–", 3: "å¢™æ¨¡", 4: "å¢™é¢æ±¡æ¸"}},
    22: {"name": "ç½‚ç²Ÿè¯†åˆ«", "classes": {0: "ç½‚ç²Ÿ"}},
    23: {"name": "ä½œç‰©å€’ä¼æ£€æµ‹", "classes": {0: "ä½œç‰©å€’ä¼"}},
    24: {"name": "æ—ä¸šä¾µå ",
         "classes": {0: "åé“²è£…è½½æœº", 1: "å‹è·¯æœº", 2: "æ··å‡åœŸæ…æ‹Œè½¦", 3: "æ¨åœŸæœº", 4: "å€¾å¸å¡è½¦", 5: "æŒ–æ˜æœº",
                     6: "å¹³åœ°æœº", 7: "å®‰å…¨å¤´ç›”", 8: "ç§»åŠ¨å¼èµ·é‡æœº", 9: "äºº", 10: "å¡”å¼èµ·é‡æœº", 11: "èƒŒå¿ƒ",
                     12: "è½®å¼è£…è½½æœº"}},
    999: {"name": "äººè„¸æ£€æµ‹", "classes": {0: "äººè„¸"}},
}

# æ¨¡å‹ç±»å‹é…ç½®
MODEL_TYPES = {
    # yolov11_720 (è¾“å…¥ 736)
    7: "yolov11_720", 8: "yolov11_720", 10: "yolov11_720", 12: "yolov11_720",
    14: "yolov11_720", 15: "yolov11_720", 16: "yolov11_720", 18: "yolov11_720",
    # yolov11 (è¾“å…¥ 640)
    6: "yolov11",
    # å˜åŒ–æ£€æµ‹
    13: "change_detection",
    # å…¶ä»–é»˜è®¤ yolov5
}


# ============================================================
# ONNX å˜åŒ–æ£€æµ‹å™¨
# ============================================================
class ONNXChangeDetector:
    """ONNX å˜åŒ–æ£€æµ‹å™¨ (SNUNet)"""

    def __init__(self, model_path: str, algo_id: int = 13):
        self.model_path = model_path
        self.algo_id = algo_id
        self.input_size = 256

        # åŠ è½½ ONNX æ¨¡å‹
        providers = ['CPUExecutionProvider']
        if 'CUDAExecutionProvider' in ort.get_available_providers():
            providers.insert(0, 'CUDAExecutionProvider')

        self.session = ort.InferenceSession(model_path, providers=providers)
        self.input_names = [inp.name for inp in self.session.get_inputs()]
        self.output_names = [out.name for out in self.session.get_outputs()]

        print(f"[ONNX] åŠ è½½å˜åŒ–æ£€æµ‹æ¨¡å‹: {model_path}")
        print(f"       è¾“å…¥: {self.input_names}")
        print(f"       è¾“å‡º: {self.output_names}")
        for inp in self.session.get_inputs():
            print(f"       {inp.name}: shape={inp.shape}")

    def preprocess(self, image: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†å•å¼ å›¾ç‰‡"""
        # è°ƒæ•´å¤§å°
        img_resized = cv2.resize(image, (self.input_size, self.input_size))
        # BGR -> RGB
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
        # HWC -> CHW
        img_chw = np.transpose(img_rgb, (2, 0, 1))
        # å½’ä¸€åŒ–åˆ° [0, 1]
        img_norm = img_chw.astype(np.float32) / 255.0
        # æ·»åŠ  batch ç»´åº¦
        return np.expand_dims(img_norm, axis=0)

    def detect(self, image1: np.ndarray, image2: np.ndarray) -> Tuple[np.ndarray, float, float]:
        """
        æ‰§è¡Œå˜åŒ–æ£€æµ‹

        Args:
            image1: ç¬¬ä¸€å¼ å›¾ç‰‡ (BGR) - æ—¶ç›¸1
            image2: ç¬¬äºŒå¼ å›¾ç‰‡ (BGR) - æ—¶ç›¸2

        Returns:
            (mask_image, change_ratio, infer_time)
        """
        orig_h, orig_w = image1.shape[:2]

        # é¢„å¤„ç†
        input1 = self.preprocess(image1)
        input2 = self.preprocess(image2)

        # æ¨ç†
        t0 = time.time()

        # SNUNet æœ‰ä¸¤ä¸ªç‹¬ç«‹è¾“å…¥: img1, img2
        if len(self.input_names) == 2:
            inputs = {
                self.input_names[0]: input1,
                self.input_names[1]: input2
            }
        else:
            combined = np.concatenate([input1, input2], axis=1)
            inputs = {self.input_names[0]: combined}

        outputs = self.session.run(None, inputs)
        infer_time = time.time() - t0

        # åå¤„ç†
        # SNUNet è¾“å‡º: [1, 2, H, W] (äºŒåˆ†ç±» logits)
        output = outputs[0]
        print(f"[å˜åŒ–æ£€æµ‹] è¾“å‡ºå½¢çŠ¶: {output.shape}, èŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")

        # ä½¿ç”¨ argmax è·å–é¢„æµ‹ç±»åˆ«
        if output.ndim == 4 and output.shape[1] == 2:
            # [1, 2, H, W] -> argmax -> [1, H, W]
            pred = np.argmax(output, axis=1)[0]  # [H, W]
            mask_binary = (pred == 1).astype(np.uint8) * 255
        elif output.ndim == 4 and output.shape[1] == 1:
            # [1, 1, H, W] -> sigmoid åé˜ˆå€¼åŒ–
            mask_binary = (output[0, 0] > 0).astype(np.uint8) * 255
        elif output.ndim == 3:
            if output.shape[0] == 2:
                pred = np.argmax(output, axis=0)
                mask_binary = (pred == 1).astype(np.uint8) * 255
            else:
                mask_binary = (output[0] > 0).astype(np.uint8) * 255
        else:
            mask_binary = (output > 0).astype(np.uint8) * 255
            if mask_binary.ndim > 2:
                mask_binary = mask_binary.squeeze()

        print(f"[å˜åŒ–æ£€æµ‹] mask å½¢çŠ¶: {mask_binary.shape}, å˜åŒ–åƒç´ : {np.sum(mask_binary > 0)}")

        # è°ƒæ•´å›åŸå§‹å¤§å°
        mask_resized = cv2.resize(mask_binary, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)

        # è®¡ç®—å˜åŒ–æ¯”ä¾‹
        change_ratio = np.sum(mask_resized > 0) / (orig_h * orig_w)

        # åˆ›å»ºå½©è‰² mask
        mask_color = np.zeros((orig_h, orig_w, 3), dtype=np.uint8)
        mask_color[mask_resized > 0] = [0, 0, 255]  # çº¢è‰²è¡¨ç¤ºå˜åŒ–åŒºåŸŸ (BGR)

        return mask_color, change_ratio, infer_time


# ============================================================
# ONNX YOLO æ£€æµ‹å™¨
# ============================================================
class ONNXYOLODetector:
    """ONNX YOLO æ£€æµ‹å™¨ (å…¼å®¹ YOLOv5/v11)"""

    def __init__(self, model_path: str, algo_id: int):
        self.model_path = model_path
        self.algo_id = algo_id
        self.model_type = MODEL_TYPES.get(algo_id, "yolov5")

        # æ ¹æ®æ¨¡å‹ç±»å‹ç¡®å®šè¾“å…¥å°ºå¯¸
        if self.model_type == "yolov11_720":
            self.input_size = 736
        elif self.model_type == "change_detection":
            self.input_size = 256
        else:
            self.input_size = 640

        # åŠ è½½ ONNX æ¨¡å‹
        providers = ['CPUExecutionProvider']
        # å¦‚æœæœ‰ CUDAï¼Œä¼˜å…ˆä½¿ç”¨
        if 'CUDAExecutionProvider' in ort.get_available_providers():
            providers.insert(0, 'CUDAExecutionProvider')

        self.session = ort.InferenceSession(model_path, providers=providers)
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name

        # è·å–è¾“å‡ºå½¢çŠ¶æ¥åˆ¤æ–­æ¨¡å‹ç±»å‹
        output_shape = self.session.get_outputs()[0].shape
        self._detect_model_format(output_shape)

        print(f"[ONNX] åŠ è½½æ¨¡å‹: algo={algo_id}, path={model_path}")
        print(f"       ç±»å‹={self.model_type}, è¾“å…¥={self.input_size}, æ ¼å¼={self._format}")

    def _detect_model_format(self, output_shape):
        """æ£€æµ‹æ¨¡å‹è¾“å‡ºæ ¼å¼"""
        # output_shape å¯èƒ½æ˜¯ [1, 25200, 85] (YOLOv5) æˆ– [1, 84, 8400] (YOLOv8/v11)
        if len(output_shape) == 3:
            dim1 = output_shape[1]
            dim2 = output_shape[2]

            if isinstance(dim1, int) and isinstance(dim2, int):
                if dim1 > dim2:
                    # YOLOv5: [1, num_preds, num_features]
                    self._format = "yolov5"
                    self._has_objectness = True
                    self._transpose = False
                else:
                    # YOLOv8/v11: [1, num_features, num_preds]
                    self._format = "yolov11"
                    self._has_objectness = False
                    self._transpose = True
            else:
                # åŠ¨æ€å½¢çŠ¶ï¼Œæ ¹æ®é…ç½®åˆ¤æ–­
                if self.model_type in ("yolov11", "yolov11_720"):
                    self._format = "yolov11"
                    self._has_objectness = False
                    self._transpose = True
                else:
                    self._format = "yolov5"
                    self._has_objectness = True
                    self._transpose = False
        else:
            self._format = "yolov5"
            self._has_objectness = True
            self._transpose = False

    def preprocess(self, image: np.ndarray) -> Tuple[np.ndarray, tuple]:
        """å›¾åƒé¢„å¤„ç† (letterbox)"""
        orig_h, orig_w = image.shape[:2]
        input_size = self.input_size

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        r = min(input_size / orig_h, input_size / orig_w)
        new_h, new_w = int(orig_h * r), int(orig_w * r)

        # ç¼©æ”¾å›¾åƒ
        img_resized = cv2.resize(image, (new_w, new_h))

        # è®¡ç®— padding
        dw, dh = (input_size - new_w) / 2, (input_size - new_h) / 2
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

        # æ·»åŠ è¾¹æ¡†
        img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right,
                                        cv2.BORDER_CONSTANT, value=(114, 114, 114))

        # è½¬æ¢é¢œè‰²ç©ºé—´å’Œæ ¼å¼
        img_rgb = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)
        img_chw = np.transpose(img_rgb, (2, 0, 1))
        img_norm = img_chw.astype(np.float32) / 255.0
        img_batch = np.expand_dims(img_norm, axis=0)

        return img_batch, (orig_h, orig_w, r, top, left)

    def detect(self, image: np.ndarray, conf_thres: float = 0.25, iou_thres: float = 0.45) -> List[Dict]:
        """æ‰§è¡Œç›®æ ‡æ£€æµ‹"""
        # é¢„å¤„ç†
        input_data, img_info = self.preprocess(image)

        # æ¨ç†
        outputs = self.session.run([self.output_name], {self.input_name: input_data})
        output = outputs[0]

        # åå¤„ç†
        return self._postprocess(output, img_info, conf_thres, iou_thres)

    def _postprocess(self, output: np.ndarray, img_info: tuple,
                     conf_thres: float, iou_thres: float) -> List[Dict]:
        """åå¤„ç†"""
        orig_h, orig_w, ratio, pad_top, pad_left = img_info

        # å»é™¤ batch ç»´åº¦
        if output.ndim == 3:
            output = output[0]

        # æ ¹æ®æ ¼å¼å¤„ç†
        if self._transpose:
            # YOLOv11: [num_features, num_preds] -> [num_preds, num_features]
            predictions = output.T
        else:
            # YOLOv5: [num_preds, num_features]
            predictions = output

        # æå–è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦
        boxes = predictions[:, :4].copy()

        if self._has_objectness:
            # YOLOv5: æœ‰ objectness
            obj_conf = predictions[:, 4]
            class_scores = predictions[:, 5:]
            class_ids = np.argmax(class_scores, axis=1)
            class_conf = np.max(class_scores, axis=1)
            scores = obj_conf * class_conf
        else:
            # YOLOv11: æ—  objectness
            class_scores = predictions[:, 4:]
            class_ids = np.argmax(class_scores, axis=1)
            scores = np.max(class_scores, axis=1)

        # ç½®ä¿¡åº¦è¿‡æ»¤
        mask = scores > conf_thres
        boxes = boxes[mask]
        scores = scores[mask]
        class_ids = class_ids[mask]

        if len(boxes) == 0:
            return []

        # xywh -> xyxy
        boxes_xyxy = np.copy(boxes)
        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2
        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2
        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2
        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2

        # å»é™¤ padding
        boxes_xyxy[:, [0, 2]] -= pad_left
        boxes_xyxy[:, [1, 3]] -= pad_top

        # ç¼©æ”¾å›åŸå›¾
        boxes_xyxy /= ratio

        # è¿‡æ»¤æ— æ•ˆæ¡†
        valid = (boxes_xyxy[:, 2] > boxes_xyxy[:, 0]) & (boxes_xyxy[:, 3] > boxes_xyxy[:, 1])
        boxes_xyxy = boxes_xyxy[valid]
        scores = scores[valid]
        class_ids = class_ids[valid]

        if len(boxes_xyxy) == 0:
            return []

        # NMS
        keep = self._nms(boxes_xyxy, scores, iou_thres)
        boxes_xyxy = boxes_xyxy[keep]
        scores = scores[keep]
        class_ids = class_ids[keep]

        # è£å‰ªåˆ°å›¾åƒè¾¹ç•Œ
        boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, orig_w)
        boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, orig_h)

        # æ„å»ºç»“æœ
        detections = []
        algo_classes = ALGO_CONFIG.get(self.algo_id, {}).get("classes", {})

        for box, score, cls_id in zip(boxes_xyxy, scores, class_ids):
            x1, y1, x2, y2 = box
            class_name = algo_classes.get(int(cls_id), f"class_{cls_id}")
            detections.append({
                "bbox": [float(x1), float(y1), float(x2), float(y2)],
                "confidence": float(score),
                "class_id": int(cls_id),
                "class_name": class_name
            })

        return detections

    @staticmethod
    def _nms(boxes: np.ndarray, scores: np.ndarray, iou_threshold: float) -> List[int]:
        """éæå¤§å€¼æŠ‘åˆ¶"""
        if len(boxes) == 0:
            return []

        x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
        areas = (x2 - x1) * (y2 - y1)
        order = scores.argsort()[::-1]

        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)

            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])

            w = np.maximum(0.0, xx2 - xx1)
            h = np.maximum(0.0, yy2 - yy1)
            inter = w * h
            iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)

            inds = np.where(iou <= iou_threshold)[0]
            order = order[inds + 1]

        return keep


# ============================================================
# æ¨¡å‹ç®¡ç†å™¨
# ============================================================
class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨"""

    def __init__(self, model_dir: str):
        self.model_dir = model_dir
        self.models: Dict[int, Any] = {}  # å¯ä»¥æ˜¯ ONNXYOLODetector æˆ– ONNXChangeDetector
        self._scan_models()

    def _scan_models(self):
        """æ‰«ææ¨¡å‹æ–‡ä»¶"""
        if not os.path.exists(self.model_dir):
            print(f"[è­¦å‘Š] æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.model_dir}")
            return

        for filename in os.listdir(self.model_dir):
            if not filename.endswith('.onnx'):
                continue

            filepath = os.path.join(self.model_dir, filename)

            # è§£æç®—æ³• ID
            # æ”¯æŒæ ¼å¼: {algo_id}.onnx, {algo_id}_720.onnx, {algo_id}_bs1.onnx
            base_name = filename.replace('.onnx', '')
            base_name = base_name.replace('_720', '').replace('_bs1', '')

            try:
                algo_id = int(base_name)
            except ValueError:
                continue

            # 720 æ¨¡å‹ä¼˜å…ˆ
            if '_720' in filename and algo_id in self.models:
                # æ›¿æ¢ä¸º 720 æ¨¡å‹
                pass
            elif algo_id in self.models:
                continue

            try:
                # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©æ£€æµ‹å™¨
                model_type = MODEL_TYPES.get(algo_id, "yolov5")
                if model_type == "change_detection":
                    self.models[algo_id] = ONNXChangeDetector(filepath, algo_id)
                else:
                    self.models[algo_id] = ONNXYOLODetector(filepath, algo_id)
            except Exception as e:
                print(f"[é”™è¯¯] åŠ è½½æ¨¡å‹å¤±è´¥: {filename}, {e}")

        print(f"[æ¨¡å‹ç®¡ç†å™¨] åŠ è½½äº† {len(self.models)} ä¸ªæ¨¡å‹")

    def get_detector(self, algo_id: int):
        """è·å–æ£€æµ‹å™¨"""
        return self.models.get(algo_id)

    def is_change_detection(self, algo_id: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå˜åŒ–æ£€æµ‹æ¨¡å‹"""
        return MODEL_TYPES.get(algo_id) == "change_detection"

    def get_available_algos(self) -> List[Dict]:
        """è·å–å¯ç”¨ç®—æ³•åˆ—è¡¨"""
        algos = []
        for algo_id in sorted(self.models.keys()):
            config = ALGO_CONFIG.get(algo_id, {})
            algos.append({
                "id": algo_id,
                "name": config.get("name", f"ç®—æ³•{algo_id}"),
                "classes": config.get("classes", {}),
                "type": "change_detection" if self.is_change_detection(algo_id) else "detection"
            })
        return algos


# ============================================================
# å›¾ç‰‡æ–‡ä»¶å¤¹ç®¡ç†å™¨
# ============================================================
class ImageFolderManager:
    """å›¾ç‰‡æ–‡ä»¶å¤¹ç®¡ç†å™¨"""

    SUPPORTED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}

    def __init__(self, image_dir: str):
        self.image_dir = image_dir

    def get_folders(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼Œå¦‚æœå½“å‰ç›®å½•æœ‰å›¾ç‰‡ä¹Ÿæ˜¾ç¤º"""
        if not os.path.exists(self.image_dir):
            return []

        folders = []

        # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æœ‰å›¾ç‰‡
        root_image_count = sum(1 for f in os.listdir(self.image_dir)
                               if os.path.isfile(os.path.join(self.image_dir, f)) and
                               Path(f).suffix.lower() in self.SUPPORTED_EXTENSIONS)
        if root_image_count > 0:
            folders.append({
                "name": "ğŸ“· å½“å‰ç›®å½•",
                "path": "__ROOT__",  # ä½¿ç”¨ç‰¹æ®Šæ ‡è¯†
                "image_count": root_image_count
            })

        # è·å–å­æ–‡ä»¶å¤¹
        for name in sorted(os.listdir(self.image_dir)):
            folder_path = os.path.join(self.image_dir, name)
            if os.path.isdir(folder_path):
                # ç»Ÿè®¡å›¾ç‰‡æ•°é‡
                image_count = sum(1 for f in os.listdir(folder_path)
                                  if Path(f).suffix.lower() in self.SUPPORTED_EXTENSIONS)
                if image_count > 0:  # åªæ˜¾ç¤ºæœ‰å›¾ç‰‡çš„æ–‡ä»¶å¤¹
                    folders.append({
                        "name": name,
                        "path": name,
                        "image_count": image_count
                    })

        return folders

    def get_images(self, folder_name: str) -> List[Dict]:
        """è·å–æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡åˆ—è¡¨"""
        if folder_name == "__ROOT__":
            folder_path = self.image_dir
        else:
            folder_path = os.path.join(self.image_dir, folder_name)

        if not os.path.exists(folder_path):
            return []

        images = []
        for filename in sorted(os.listdir(folder_path)):
            filepath = os.path.join(folder_path, filename)
            if os.path.isfile(filepath) and Path(filename).suffix.lower() in self.SUPPORTED_EXTENSIONS:
                # è·å–æ–‡ä»¶å¤§å°
                size = os.path.getsize(filepath)
                if folder_name == "__ROOT__":
                    rel_path = filename
                else:
                    rel_path = f"{folder_name}/{filename}"
                images.append({
                    "name": filename,
                    "path": rel_path,
                    "size": size,
                    "size_str": self._format_size(size)
                })

        return images

    def get_image_path(self, relative_path: str) -> Optional[str]:
        """è·å–å›¾ç‰‡å®Œæ•´è·¯å¾„"""
        full_path = os.path.join(self.image_dir, relative_path)
        if os.path.exists(full_path):
            return full_path
        return None

    @staticmethod
    def _format_size(size: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} TB"


# ============================================================
# Flask åº”ç”¨
# ============================================================
app = Flask(__name__, static_folder=None)
CORS(app)

model_manager: ModelManager = None
image_manager: ImageFolderManager = None


@app.route('/')
def index():
    """è¿”å›å‰ç«¯é¡µé¢"""
    return send_from_directory('.', 'onnx_demoå‰¯æœ¬.html')


@app.route('/api/config', methods=['POST', 'GET'])
def api_config():
    """è·å–æˆ–æ›´æ–°é…ç½®"""
    global model_manager, image_manager

    if request.method == 'GET':
        return jsonify({
            "code": 200,
            "data": {
                "model_dir": model_manager.model_dir if model_manager else MODEL_DIR,
                "image_dir": image_manager.image_dir if image_manager else IMAGE_DIR
            }
        })

    # POST - æ›´æ–°é…ç½®
    try:
        data = request.get_json()
        new_model_dir = data.get('model_dir')
        new_image_dir = data.get('image_dir')

        # æ›´æ–°æ¨¡å‹ç®¡ç†å™¨
        if new_model_dir:
            if os.path.exists(new_model_dir):
                model_manager = ModelManager(new_model_dir)
                print(f"[é…ç½®] æ¨¡å‹ç›®å½•å·²æ›´æ–°: {new_model_dir}")
            else:
                return jsonify({"code": 400, "message": f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {new_model_dir}"})

        # æ›´æ–°å›¾ç‰‡ç®¡ç†å™¨
        if new_image_dir:
            if os.path.exists(new_image_dir):
                image_manager = ImageFolderManager(new_image_dir)
                print(f"[é…ç½®] å›¾ç‰‡ç›®å½•å·²æ›´æ–°: {new_image_dir}")
            else:
                return jsonify({"code": 400, "message": f"å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {new_image_dir}"})

        return jsonify({
            "code": 200,
            "message": "é…ç½®å·²æ›´æ–°",
            "data": {
                "model_dir": model_manager.model_dir if model_manager else new_model_dir,
                "image_dir": image_manager.image_dir if image_manager else new_image_dir
            }
        })
    except Exception as e:
        return jsonify({"code": 500, "message": str(e)})


@app.route('/api/algorithms')
def get_algorithms():
    """è·å–å¯ç”¨ç®—æ³•åˆ—è¡¨"""
    return jsonify({
        "code": 200,
        "data": model_manager.get_available_algos()
    })


@app.route('/api/folders')
def get_folders():
    """è·å–å›¾ç‰‡æ–‡ä»¶å¤¹åˆ—è¡¨"""
    return jsonify({
        "code": 200,
        "data": image_manager.get_folders()
    })


@app.route('/api/images/<path:folder_name>')
def get_images(folder_name: str):
    """è·å–æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡åˆ—è¡¨"""
    return jsonify({
        "code": 200,
        "data": image_manager.get_images(folder_name)
    })


@app.route('/api/image/<path:image_path>')
def get_image(image_path: str):
    """è·å–å›¾ç‰‡æ–‡ä»¶"""
    full_path = image_manager.get_image_path(image_path)
    if full_path:
        return send_file(full_path)
    return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404


@app.route('/api/thumb/<path:image_path>')
def get_thumbnail(image_path: str):
    """è·å–å›¾ç‰‡ç¼©ç•¥å›¾"""
    full_path = image_manager.get_image_path(image_path)
    if not full_path:
        return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404

    try:
        # è¯»å–å›¾ç‰‡ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
        image = cv2.imdecode(np.fromfile(full_path, dtype=np.uint8), cv2.IMREAD_COLOR)
        if image is None:
            return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡"}), 400

        # ç”Ÿæˆç¼©ç•¥å›¾ (æœ€å¤§ 100x100)
        h, w = image.shape[:2]
        max_size = 100
        if w > h:
            new_w = max_size
            new_h = int(h * max_size / w)
        else:
            new_h = max_size
            new_w = int(w * max_size / h)

        thumb = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)

        # ç¼–ç ä¸º JPEG
        _, buffer = cv2.imencode('.jpg', thumb, [cv2.IMWRITE_JPEG_QUALITY, 70])

        return send_file(
            BytesIO(buffer.tobytes()),
            mimetype='image/jpeg'
        )
    except Exception as e:
        return jsonify({"code": 500, "message": str(e)}), 500


@app.route('/api/detect', methods=['POST'])
def detect():
    """æ‰§è¡Œç›®æ ‡æ£€æµ‹"""
    data = request.json

    algo_id = data.get('algorithm_id')
    image_path = data.get('image_path')
    conf_threshold = data.get('conf_threshold', DEFAULT_CONF)
    iou_threshold = data.get('iou_threshold', DEFAULT_IOU)

    if not algo_id:
        return jsonify({"code": 400, "message": "ç¼ºå°‘ algorithm_id"}), 400

    if not image_path:
        return jsonify({"code": 400, "message": "ç¼ºå°‘ image_path"}), 400

    # è·å–æ£€æµ‹å™¨
    detector = model_manager.get_detector(algo_id)
    if not detector:
        return jsonify({"code": 404, "message": f"ç®—æ³• {algo_id} ä¸å­˜åœ¨"}), 404

    # è·å–å›¾ç‰‡
    full_path = image_manager.get_image_path(image_path)
    if not full_path:
        return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404

    # è¯»å–å›¾ç‰‡ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
    try:
        # Windows ä¸­æ–‡è·¯å¾„éœ€è¦ç‰¹æ®Šå¤„ç†
        image = cv2.imdecode(np.fromfile(full_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    except Exception as e:
        return jsonify({"code": 400, "message": f"è¯»å–å›¾ç‰‡å¤±è´¥: {e}"}), 400

    if image is None:
        return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼"}), 400

    img_h, img_w = image.shape[:2]

    # æ‰§è¡Œæ£€æµ‹
    t0 = time.time()
    try:
        detections = detector.detect(image, conf_threshold, iou_threshold)
    except Exception as e:
        return jsonify({"code": 500, "message": f"æ£€æµ‹å¤±è´¥: {e}"}), 500

    detect_time = time.time() - t0

    # ç»˜åˆ¶æ£€æµ‹ç»“æœ
    result_image = draw_detections(image, detections)

    # ç¼–ç ä¸º base64
    _, buffer = cv2.imencode('.jpg', result_image, [cv2.IMWRITE_JPEG_QUALITY, 90])
    result_b64 = base64.b64encode(buffer).decode('utf-8')

    # æ„å»ºå“åº”
    algo_config = ALGO_CONFIG.get(algo_id, {})

    return jsonify({
        "code": 200,
        "data": {
            "algorithm_id": algo_id,
            "algorithm_name": algo_config.get("name", f"ç®—æ³•{algo_id}"),
            "image_width": img_w,
            "image_height": img_h,
            "detections": detections,
            "total_count": len(detections),
            "detect_time": round(detect_time, 3),
            "result_image": f"data:image/jpeg;base64,{result_b64}"
        }
    })


@app.route('/api/detect_change', methods=['POST'])
def detect_change():
    """æ‰§è¡Œå˜åŒ–æ£€æµ‹ï¼ˆéœ€è¦ä¸¤å¼ å›¾ç‰‡ï¼‰"""
    data = request.json

    algo_id = data.get('algorithm_id', 13)
    image_path1 = data.get('image_path1')
    image_path2 = data.get('image_path2')

    if not image_path1 or not image_path2:
        return jsonify({"code": 400, "message": "éœ€è¦æä¾›ä¸¤å¼ å›¾ç‰‡è·¯å¾„ (image_path1, image_path2)"}), 400

    # è·å–æ£€æµ‹å™¨
    detector = model_manager.get_detector(algo_id)
    if not detector:
        return jsonify({"code": 404, "message": f"ç®—æ³• {algo_id} ä¸å­˜åœ¨"}), 404

    if not model_manager.is_change_detection(algo_id):
        return jsonify({"code": 400, "message": f"ç®—æ³• {algo_id} ä¸æ˜¯å˜åŒ–æ£€æµ‹æ¨¡å‹"}), 400

    # è·å–å›¾ç‰‡1
    full_path1 = image_manager.get_image_path(image_path1)
    if not full_path1:
        return jsonify({"code": 404, "message": f"å›¾ç‰‡1ä¸å­˜åœ¨: {image_path1}"}), 404

    # è·å–å›¾ç‰‡2
    full_path2 = image_manager.get_image_path(image_path2)
    if not full_path2:
        return jsonify({"code": 404, "message": f"å›¾ç‰‡2ä¸å­˜åœ¨: {image_path2}"}), 404

    # è¯»å–å›¾ç‰‡
    try:
        image1_orig = cv2.imdecode(np.fromfile(full_path1, dtype=np.uint8), cv2.IMREAD_COLOR)
        image2_orig = cv2.imdecode(np.fromfile(full_path2, dtype=np.uint8), cv2.IMREAD_COLOR)
    except Exception as e:
        return jsonify({"code": 400, "message": f"è¯»å–å›¾ç‰‡å¤±è´¥: {e}"}), 400

    if image1_orig is None or image2_orig is None:
        return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡"}), 400

    # å˜åŒ–æ£€æµ‹éœ€è¦ç»Ÿä¸€å°ºå¯¸åˆ° 256x256
    input_size = 256
    image1 = cv2.resize(image1_orig, (input_size, input_size))
    image2 = cv2.resize(image2_orig, (input_size, input_size))

    # æ‰§è¡Œå˜åŒ–æ£€æµ‹
    try:
        mask_color, change_ratio, detect_time = detector.detect(image1, image2)
    except Exception as e:
        return jsonify({"code": 500, "message": f"æ£€æµ‹å¤±è´¥: {e}"}), 500

    # åˆ›å»ºå åŠ ç»“æœå›¾
    overlay = image2.copy()
    overlay[mask_color[:, :, 2] > 0] = [0, 0, 255]  # çº¢è‰²æ ‡è®°å˜åŒ–åŒºåŸŸ
    blended = cv2.addWeighted(image2, 0.7, overlay, 0.3, 0)

    # ç¼–ç ç»“æœå›¾
    _, buffer1 = cv2.imencode('.jpg', image1, [cv2.IMWRITE_JPEG_QUALITY, 90])
    _, buffer2 = cv2.imencode('.jpg', image2, [cv2.IMWRITE_JPEG_QUALITY, 90])
    _, buffer_mask = cv2.imencode('.jpg', mask_color, [cv2.IMWRITE_JPEG_QUALITY, 90])
    _, buffer_blend = cv2.imencode('.jpg', blended, [cv2.IMWRITE_JPEG_QUALITY, 90])

    image1_b64 = base64.b64encode(buffer1).decode('utf-8')
    image2_b64 = base64.b64encode(buffer2).decode('utf-8')
    mask_b64 = base64.b64encode(buffer_mask).decode('utf-8')
    blend_b64 = base64.b64encode(buffer_blend).decode('utf-8')

    algo_config = ALGO_CONFIG.get(algo_id, {})

    return jsonify({
        "code": 200,
        "data": {
            "algorithm_id": algo_id,
            "algorithm_name": algo_config.get("name", "å˜åŒ–æ£€æµ‹"),
            "image_width": input_size,
            "image_height": input_size,
            "change_ratio": round(change_ratio * 100, 2),  # ç™¾åˆ†æ¯”
            "detect_time": round(detect_time, 3),
            "image1": f"data:image/jpeg;base64,{image1_b64}",
            "image2": f"data:image/jpeg;base64,{image2_b64}",
            "mask_image": f"data:image/jpeg;base64,{mask_b64}",
            "result_image": f"data:image/jpeg;base64,{blend_b64}"
        }
    })


def draw_detections(image: np.ndarray, detections: List[Dict]) -> np.ndarray:
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœï¼ˆæ”¯æŒä¸­æ–‡ï¼‰"""
    from PIL import Image, ImageDraw, ImageFont

    # è½¬æ¢ä¸º PIL å›¾åƒ
    result = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(result)
    draw = ImageDraw.Draw(pil_image)

    # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
    font = None
    font_size = 20
    # Windows å¸¸è§ä¸­æ–‡å­—ä½“è·¯å¾„
    font_paths = [
        "C:/Windows/Fonts/msyh.ttc",  # å¾®è½¯é›…é»‘
        "C:/Windows/Fonts/simsun.ttc",  # å®‹ä½“
        "C:/Windows/Fonts/simhei.ttf",  # é»‘ä½“
        "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",  # Linux
        "/System/Library/Fonts/PingFang.ttc",  # macOS
    ]
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                font = ImageFont.truetype(font_path, font_size)
                break
            except:
                continue

    if font is None:
        # ä½¿ç”¨é»˜è®¤å­—ä½“
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()

    # é¢œè‰²åˆ—è¡¨ (RGB)
    colors = [
        (0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (128, 255, 0), (255, 128, 0),
        (128, 0, 255), (0, 128, 255), (255, 0, 128), (0, 255, 128),
    ]

    for det in detections:
        bbox = det["bbox"]
        x1, y1, x2, y2 = map(int, bbox)
        class_id = det["class_id"]
        class_name = det["class_name"]
        confidence = det["confidence"]

        # é€‰æ‹©é¢œè‰²
        color = colors[class_id % len(colors)]

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)

        # ç»˜åˆ¶æ ‡ç­¾
        label = f"{class_name} {confidence:.2f}"

        # è·å–æ–‡æœ¬å¤§å°
        try:
            bbox_text = draw.textbbox((0, 0), label, font=font)
            text_w = bbox_text[2] - bbox_text[0]
            text_h = bbox_text[3] - bbox_text[1]
        except:
            text_w, text_h = draw.textsize(label, font=font) if hasattr(draw, 'textsize') else (len(label) * 10, 20)

        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        label_y = max(y1 - text_h - 8, 0)
        draw.rectangle([x1, label_y, x1 + text_w + 10, label_y + text_h + 6], fill=color)

        # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
        draw.text((x1 + 5, label_y + 2), label, fill=(255, 255, 255), font=font)

    # è½¬æ¢å› OpenCV æ ¼å¼
    result = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    return result


def main():
    global model_manager, image_manager

    print("=" * 60)
    print("ONNX å¯è§†åŒ–æ¼”ç¤ºæœåŠ¡")
    print("=" * 60)
    print(f"æ¨¡å‹ç›®å½•: {MODEL_DIR}")
    print(f"å›¾ç‰‡ç›®å½•: {IMAGE_DIR}")
    print(f"æœåŠ¡åœ°å€: http://{SERVER_HOST}:{SERVER_PORT}")
    print(f"é»˜è®¤ç½®ä¿¡åº¦: {DEFAULT_CONF}")
    print(f"é»˜è®¤IOU: {DEFAULT_IOU}")
    print("=" * 60)

    # æ£€æŸ¥ç›®å½•
    if not os.path.exists(MODEL_DIR):
        print(f"\n[è­¦å‘Š] æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: {MODEL_DIR}")
        os.makedirs(MODEL_DIR, exist_ok=True)
        print(f"[æç¤º] è¯·å°† .onnx æ¨¡å‹æ–‡ä»¶æ”¾å…¥ {MODEL_DIR} ç›®å½•")

    if not os.path.exists(IMAGE_DIR):
        print(f"\n[è­¦å‘Š] å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: {IMAGE_DIR}")
        os.makedirs(IMAGE_DIR, exist_ok=True)
        print(f"[æç¤º] è¯·åœ¨ {IMAGE_DIR} ç›®å½•ä¸‹åˆ›å»ºå­æ–‡ä»¶å¤¹å¹¶æ”¾å…¥æµ‹è¯•å›¾ç‰‡")

    # åˆå§‹åŒ–ç®¡ç†å™¨
    model_manager = ModelManager(MODEL_DIR)
    image_manager = ImageFolderManager(IMAGE_DIR)

    # å¯åŠ¨æœåŠ¡
    print(f"\nğŸš€ æœåŠ¡å·²å¯åŠ¨: http://localhost:{SERVER_PORT}")
    print(f"   æµè§ˆå™¨è®¿é—®ä¸Šè¿°åœ°å€å³å¯ä½¿ç”¨\n")
    app.run(host=SERVER_HOST, port=SERVER_PORT, debug=False, threaded=True)


if __name__ == '__main__':
    main()