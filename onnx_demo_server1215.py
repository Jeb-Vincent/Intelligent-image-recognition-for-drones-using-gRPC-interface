#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ONNX å¯è§†åŒ–æ¼”ç¤ºæœåŠ¡ (å¢å¼ºç‰ˆ)

åŠŸèƒ½:
- æ‰¹é‡æ£€æµ‹æ•´ä¸ªç›®å½•ä¸‹çš„å›¾ç‰‡
- è®¡ç®—æ£€æµ‹æ­£ç¡®ç‡ï¼ˆåŸºäºIoUåŒ¹é…ï¼‰
- è‡ªåŠ¨ç­›é€‰é«˜æ­£ç¡®ç‡å›¾ç‰‡å¹¶ä¿å­˜
- æ”¯æŒåŸå›¾ã€é¢„æµ‹å›¾ã€çœŸå®æ ‡ç­¾å›¾å¯¹æ¯”å±•ç¤º

ä½¿ç”¨æ–¹æ³•:
    ç›´æ¥è¿è¡Œ: python onnx_demo_server.py
"""

import os
import sys
import base64
import time
import json
import shutil
import random
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from io import BytesIO

import cv2
import numpy as np
import onnxruntime as ort
from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS

# ============================================================
# â˜…â˜…â˜… é…ç½®åŒºåŸŸ - åœ¨æ­¤å¤„ä¿®æ”¹é…ç½® â˜…â˜…â˜…
# ============================================================

SERVER_HOST = '0.0.0.0'
SERVER_PORT = 8082

MODEL_DIR = './'
IMAGE_DIR = './test_images'

DEFAULT_CONF = 0.25
DEFAULT_IOU = 0.45

# ============================================================

ALGO_CONFIG = {
    1: {"name": "æ¾çº¿è™«å®³è¯†åˆ«", "classes": {0: "æ­»äº¡", 1: "é‡åº¦æ‚£ç—…", 2: "è½»åº¦æ‚£ç—…"}},
    2: {"name": "æ²³é“æ·¤ç§¯è¯†åˆ«", "classes": {0: "æ°´æ±¡æŸ“", 1: "æ¼‚æµ®ç¢ç‰‡", 2: "åºŸå¼ƒèˆ¹åª", 3: "æ¸”ä¸šå’Œæ°´äº§å…»æ®–", 4: "åƒåœ¾"}},
    3: {"name": "æ¼‚æµ®ç‰©è¯†åˆ«",
        "classes": {0: "ç“¶å­", 1: "è‰", 2: "æ ‘æ", 3: "ç‰›å¥¶ç›’", 4: "å¡‘æ–™è¢‹", 5: "å¡‘æ–™åƒåœ¾è¢‹", 6: "çƒ", 7: "å¶å­"}},
    4: {"name": "æ¸¸æ³³æ¶‰æ°´è¯†åˆ«",
        "classes": {0: "å¿½ç•¥", 1: "æ¸¸æ³³è€…", 2: "èˆ¹", 3: "æ°´ä¸Šæ‘©æ‰˜è‰‡", 4: "æ•‘ç”Ÿè®¾å¤‡", 5: "æµ®æ ‡"}},
    5: {"name": "è½¦ç‰Œè¯†åˆ«", "classes": {0: "è½¦ç‰Œ"}},
    6: {"name": "äº¤é€šæ‹¥å µè¯†åˆ«", "classes": {0: "è½¦è¾†"}},
    7: {"name": "è·¯é¢ç ´æŸè¯†åˆ«",
        "classes": {0: "é¾Ÿè£‚", 1: "çºµå‘è£‚ç¼", 2: "çºµå‘ä¿®è¡¥å—", 3: "æ£€æŸ¥äº•äº•ç›–", 4: "å‘æ´", 5: "æ¨ªå‘è£‚ç¼",
                    6: "æ¨ªå‘ä¿®è¡¥å—"}},
    8: {"name": "è·¯é¢æ±¡æŸ“",
        "classes": {0: "è£‚ç¼", 1: "ç§¯æ°´", 2: "è·¯é¢æ¾æ•£", 3: "æ³¥æ³é“è·¯", 4: "è·¯è¾¹åƒåœ¾", 5: "å‘æ´"}},
    9: {"name": "äººç¾¤èšé›†è¯†åˆ«", "classes": {0: "è½¦", 1: "äºº"}},
    10: {"name": "éæ³•å‚é’“è¯†åˆ«", "classes": {0: "æ°´è¾¹é’“é±¼", 1: "æ¸¸æ³³æººæ°´", 2: "é’“é±¼ä¼", 3: "èˆ¹"}},
    11: {"name": "æ–½å·¥è¯†åˆ«", "classes": {0: "èµ·é‡æœº", 1: "æŒ–æ˜æœº", 2: "æ‹–æ‹‰æœº", 3: "å¡è½¦"}},
    12: {"name": "ç§¸ç§†ç„šçƒ§", "classes": {0: "ç§¸ç§†å †"}},
    13: {"name": "å˜åŒ–æ£€æµ‹", "classes": {0: "æ— å˜åŒ–", 1: "å˜åŒ–åŒºåŸŸ"}},
    14: {"name": "å é“ç»è¥è¯†åˆ«", "classes": {0: "å é“ç»è¥"}},
    15: {"name": "åƒåœ¾å †æ”¾è¯†åˆ«",
         "classes": {0: "é•¿æ¤…", 1: "å•†ä¸šåƒåœ¾", 2: "éæ³•å€¾å€’ç‚¹", 3: "ç»¿åœ°", 4: "å­”æ´", 5: "æ³½è¥¿æŠ¤æ ", 6: "åœ°å—",
                     7: "åŸææ–™", 8: "ç”Ÿæ´»åƒåœ¾"}},
    16: {"name": "è£¸åœŸæœªè¦†ç›–è¯†åˆ«", "classes": {0: "åƒåœ¾", 1: "è£¸åœŸ"}},
    17: {"name": "å»ºæ§åŒºè¿å»ºè¯†åˆ«", "classes": {0: "è“è‰²å¤©ç¯·", 1: "å…¶ä»–è¿å»º", 2: "æ”¹è£…ç»¿è‰²å°å±‹"}},
    18: {"name": "çƒŸç«è¯†åˆ«", "classes": {0: "çƒŸé›¾", 1: "ç«"}},
    19: {"name": "å…‰ä¼æ¿ç¼ºé™·æ£€æµ‹", "classes": {0: "æœ‰ç¼ºé™·çš„å…‰ä¼ç”µæ± "}},
    20: {"name": "å›­åŒºå¤œé—´å…¥ä¾µæ£€æµ‹", "classes": {0: "äºº", 1: "è½¦", 2: "è‡ªè¡Œè½¦"}},
    21: {"name": "å›­åŒºå¤–ç«‹é¢ç—…å®³è¯†åˆ«",
         "classes": {0: "å¢™ä½“è…èš€", 1: "å¢™ä½“å¼€è£‚", 2: "å¢™ä½“åŠ£åŒ–", 3: "å¢™æ¨¡", 4: "å¢™é¢æ±¡æ¸"}},
    22: {"name": "ç½‚ç²Ÿè¯†åˆ«", "classes": {0: "ç½‚ç²Ÿ"}},
    23: {"name": "ä½œç‰©å€’ä¼æ£€æµ‹", "classes": {0: "ä½œç‰©å€’ä¼"}},
    24: {"name": "æ—ä¸šä¾µå ",
         "classes": {0: "åé“²è£…è½½æœº", 1: "å‹è·¯æœº", 2: "æ··å‡åœŸæ…æ‹Œè½¦", 3: "æ¨åœŸæœº", 4: "å€¾å¸å¡è½¦", 5: "æŒ–æ˜æœº",
                     6: "å¹³åœ°æœº", 7: "å®‰å…¨å¤´ç›”", 8: "ç§»åŠ¨å¼èµ·é‡æœº", 9: "äºº", 10: "å¡”å¼èµ·é‡æœº", 11: "èƒŒå¿ƒ",
                     12: "è½®å¼è£…è½½æœº"}},
    999: {"name": "äººè„¸æ£€æµ‹", "classes": {0: "äººè„¸"}},
}

MODEL_TYPES = {
    7: "yolov11_720", 8: "yolov11_720", 10: "yolov11_720", 12: "yolov11_720",
    14: "yolov11_720", 15: "yolov11_720", 16: "yolov11_720", 18: "yolov11_720",
    6: "yolov11",
    13: "change_detection",
}


# ============================================================
# æ­£ç¡®ç‡è®¡ç®—å·¥å…·
# ============================================================
def calculate_iou(box1, box2):
    """è®¡ç®—ä¸¤ä¸ªæ¡†çš„IoU"""
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    xi1 = max(x1_1, x1_2)
    yi1 = max(y1_1, y1_2)
    xi2 = min(x2_1, x2_2)
    yi2 = min(y2_1, y2_2)
    
    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
    
    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
    
    union_area = box1_area + box2_area - inter_area
    
    if union_area == 0:
        return 0
    
    return inter_area / union_area


def parse_yolo_label(label_path: str, img_width: int, img_height: int) -> List[Dict]:
    """è§£æYOLOæ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶"""
    labels = []
    if not os.path.exists(label_path):
        return labels
    
    try:
        with open(label_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    cx = float(parts[1]) * img_width
                    cy = float(parts[2]) * img_height
                    w = float(parts[3]) * img_width
                    h = float(parts[4]) * img_height
                    
                    x1 = cx - w / 2
                    y1 = cy - h / 2
                    x2 = cx + w / 2
                    y2 = cy + h / 2
                    
                    labels.append({
                        'class_id': class_id,
                        'bbox': [x1, y1, x2, y2]
                    })
    except Exception as e:
        print(f"[è­¦å‘Š] è§£ææ ‡ç­¾æ–‡ä»¶å¤±è´¥: {label_path}, {e}")
    
    return labels


def calculate_accuracy(predictions: List[Dict], ground_truths: List[Dict], iou_threshold: float = 0.5) -> float:
    """
    è®¡ç®—æ£€æµ‹æ­£ç¡®ç‡
    æ­£ç¡®ç‡ = æ­£ç¡®åŒ¹é…æ•° / max(é¢„æµ‹æ•°, çœŸå®æ•°)
    """
    if len(ground_truths) == 0 and len(predictions) == 0:
        return 1.0
    
    if len(ground_truths) == 0 or len(predictions) == 0:
        return 0.0
    
    matched_gt = set()
    matched_pred = set()
    
    # è´ªå©ªåŒ¹é…ï¼šæŒ‰IoUä»é«˜åˆ°ä½åŒ¹é…
    matches = []
    for i, pred in enumerate(predictions):
        for j, gt in enumerate(ground_truths):
            if pred.get('class_id', -1) == gt.get('class_id', -2):
                iou = calculate_iou(pred['bbox'], gt['bbox'])
                if iou >= iou_threshold:
                    matches.append((iou, i, j))
    
    # æŒ‰IoUæ’åº
    matches.sort(reverse=True)
    
    # è´ªå©ªé€‰æ‹©
    for iou, pred_idx, gt_idx in matches:
        if pred_idx not in matched_pred and gt_idx not in matched_gt:
            matched_pred.add(pred_idx)
            matched_gt.add(gt_idx)
    
    correct_count = len(matched_gt)
    total = max(len(predictions), len(ground_truths))
    
    return correct_count / total if total > 0 else 0.0


def detections_to_yolo_format(detections: List[Dict], img_width: int, img_height: int) -> str:
    """å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸ºYOLOæ ¼å¼çš„æ ‡ç­¾å­—ç¬¦ä¸²"""
    lines = []
    for det in detections:
        bbox = det['bbox']
        x1, y1, x2, y2 = bbox
        
        cx = (x1 + x2) / 2 / img_width
        cy = (y1 + y2) / 2 / img_height
        w = (x2 - x1) / img_width
        h = (y2 - y1) / img_height
        
        class_id = det['class_id']
        lines.append(f"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}")
    
    return '\n'.join(lines)


# ============================================================
# ONNX å˜åŒ–æ£€æµ‹å™¨
# ============================================================
class ONNXChangeDetector:
    """ONNX å˜åŒ–æ£€æµ‹å™¨ (SNUNet)"""

    def __init__(self, model_path: str, algo_id: int = 13):
        self.model_path = model_path
        self.algo_id = algo_id
        self.input_size = 256

        providers = ['CPUExecutionProvider']
        if 'CUDAExecutionProvider' in ort.get_available_providers():
            providers.insert(0, 'CUDAExecutionProvider')

        self.session = ort.InferenceSession(model_path, providers=providers)
        self.input_names = [inp.name for inp in self.session.get_inputs()]
        self.output_names = [out.name for out in self.session.get_outputs()]

        print(f"[ONNX] åŠ è½½å˜åŒ–æ£€æµ‹æ¨¡å‹: {model_path}")

    def preprocess(self, image: np.ndarray) -> np.ndarray:
        img_resized = cv2.resize(image, (self.input_size, self.input_size))
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
        img_chw = np.transpose(img_rgb, (2, 0, 1))
        img_norm = img_chw.astype(np.float32) / 255.0
        return np.expand_dims(img_norm, axis=0)

    def detect(self, image1: np.ndarray, image2: np.ndarray) -> Tuple[np.ndarray, float, float]:
        orig_h, orig_w = image1.shape[:2]
        input1 = self.preprocess(image1)
        input2 = self.preprocess(image2)

        t0 = time.time()

        if len(self.input_names) == 2:
            inputs = {self.input_names[0]: input1, self.input_names[1]: input2}
        else:
            combined = np.concatenate([input1, input2], axis=1)
            inputs = {self.input_names[0]: combined}

        outputs = self.session.run(None, inputs)
        infer_time = time.time() - t0

        output = outputs[0]

        if output.ndim == 4 and output.shape[1] == 2:
            pred = np.argmax(output, axis=1)[0]
            mask_binary = (pred == 1).astype(np.uint8) * 255
        elif output.ndim == 4 and output.shape[1] == 1:
            mask_binary = (output[0, 0] > 0).astype(np.uint8) * 255
        elif output.ndim == 3:
            if output.shape[0] == 2:
                pred = np.argmax(output, axis=0)
                mask_binary = (pred == 1).astype(np.uint8) * 255
            else:
                mask_binary = (output[0] > 0).astype(np.uint8) * 255
        else:
            mask_binary = (output > 0).astype(np.uint8) * 255
            if mask_binary.ndim > 2:
                mask_binary = mask_binary.squeeze()

        mask_resized = cv2.resize(mask_binary, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)
        change_ratio = np.sum(mask_resized > 0) / (orig_h * orig_w)

        mask_color = np.zeros((orig_h, orig_w, 3), dtype=np.uint8)
        mask_color[mask_resized > 0] = [0, 0, 255]

        return mask_color, change_ratio, infer_time


# ============================================================
# ONNX YOLO æ£€æµ‹å™¨
# ============================================================
class ONNXYOLODetector:
    """ONNX YOLO æ£€æµ‹å™¨ (å…¼å®¹ YOLOv5/v11)"""

    def __init__(self, model_path: str, algo_id: int):
        self.model_path = model_path
        self.algo_id = algo_id
        self.model_type = MODEL_TYPES.get(algo_id, "yolov5")

        if self.model_type == "yolov11_720":
            self.input_size = 736
        elif self.model_type == "change_detection":
            self.input_size = 256
        else:
            self.input_size = 640

        providers = ['CPUExecutionProvider']
        if 'CUDAExecutionProvider' in ort.get_available_providers():
            providers.insert(0, 'CUDAExecutionProvider')

        self.session = ort.InferenceSession(model_path, providers=providers)
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name

        output_shape = self.session.get_outputs()[0].shape
        self._detect_model_format(output_shape)

        print(f"[ONNX] åŠ è½½æ¨¡å‹: algo={algo_id}, path={model_path}")
        print(f"       ç±»å‹={self.model_type}, è¾“å…¥={self.input_size}, æ ¼å¼={self._format}")

    def _detect_model_format(self, output_shape):
        if len(output_shape) == 3:
            dim1 = output_shape[1]
            dim2 = output_shape[2]

            if isinstance(dim1, int) and isinstance(dim2, int):
                if dim1 > dim2:
                    self._format = "yolov5"
                    self._has_objectness = True
                    self._transpose = False
                else:
                    self._format = "yolov11"
                    self._has_objectness = False
                    self._transpose = True
            else:
                if self.model_type in ("yolov11", "yolov11_720"):
                    self._format = "yolov11"
                    self._has_objectness = False
                    self._transpose = True
                else:
                    self._format = "yolov5"
                    self._has_objectness = True
                    self._transpose = False
        else:
            self._format = "yolov5"
            self._has_objectness = True
            self._transpose = False

    def preprocess(self, image: np.ndarray) -> Tuple[np.ndarray, tuple]:
        orig_h, orig_w = image.shape[:2]
        input_size = self.input_size

        r = min(input_size / orig_h, input_size / orig_w)
        new_h, new_w = int(orig_h * r), int(orig_w * r)

        img_resized = cv2.resize(image, (new_w, new_h))

        dw, dh = (input_size - new_w) / 2, (input_size - new_h) / 2
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

        img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right,
                                        cv2.BORDER_CONSTANT, value=(114, 114, 114))

        img_rgb = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)
        img_chw = np.transpose(img_rgb, (2, 0, 1))
        img_norm = img_chw.astype(np.float32) / 255.0
        img_batch = np.expand_dims(img_norm, axis=0)

        return img_batch, (orig_h, orig_w, r, top, left)

    def detect(self, image: np.ndarray, conf_thres: float = 0.25, iou_thres: float = 0.45) -> List[Dict]:
        input_data, img_info = self.preprocess(image)
        outputs = self.session.run([self.output_name], {self.input_name: input_data})
        output = outputs[0]
        return self._postprocess(output, img_info, conf_thres, iou_thres)

    def _postprocess(self, output: np.ndarray, img_info: tuple,
                     conf_thres: float, iou_thres: float) -> List[Dict]:
        orig_h, orig_w, ratio, pad_top, pad_left = img_info

        if output.ndim == 3:
            output = output[0]

        if self._transpose:
            predictions = output.T
        else:
            predictions = output

        boxes = predictions[:, :4].copy()

        if self._has_objectness:
            obj_conf = predictions[:, 4]
            class_scores = predictions[:, 5:]
            class_ids = np.argmax(class_scores, axis=1)
            class_conf = np.max(class_scores, axis=1)
            scores = obj_conf * class_conf
        else:
            class_scores = predictions[:, 4:]
            class_ids = np.argmax(class_scores, axis=1)
            scores = np.max(class_scores, axis=1)

        mask = scores > conf_thres
        boxes = boxes[mask]
        scores = scores[mask]
        class_ids = class_ids[mask]

        if len(boxes) == 0:
            return []

        boxes_xyxy = np.copy(boxes)
        boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2
        boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2
        boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2
        boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2

        boxes_xyxy[:, [0, 2]] -= pad_left
        boxes_xyxy[:, [1, 3]] -= pad_top
        boxes_xyxy /= ratio

        valid = (boxes_xyxy[:, 2] > boxes_xyxy[:, 0]) & (boxes_xyxy[:, 3] > boxes_xyxy[:, 1])
        boxes_xyxy = boxes_xyxy[valid]
        scores = scores[valid]
        class_ids = class_ids[valid]

        if len(boxes_xyxy) == 0:
            return []

        keep = self._nms(boxes_xyxy, scores, iou_thres)
        boxes_xyxy = boxes_xyxy[keep]
        scores = scores[keep]
        class_ids = class_ids[keep]

        boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, orig_w)
        boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, orig_h)

        detections = []
        algo_classes = ALGO_CONFIG.get(self.algo_id, {}).get("classes", {})

        for box, score, cls_id in zip(boxes_xyxy, scores, class_ids):
            x1, y1, x2, y2 = box
            class_name = algo_classes.get(int(cls_id), f"class_{cls_id}")
            detections.append({
                "bbox": [float(x1), float(y1), float(x2), float(y2)],
                "confidence": float(score),
                "class_id": int(cls_id),
                "class_name": class_name
            })

        return detections

    @staticmethod
    def _nms(boxes: np.ndarray, scores: np.ndarray, iou_threshold: float) -> List[int]:
        if len(boxes) == 0:
            return []

        x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
        areas = (x2 - x1) * (y2 - y1)
        order = scores.argsort()[::-1]

        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)

            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])

            w = np.maximum(0.0, xx2 - xx1)
            h = np.maximum(0.0, yy2 - yy1)
            inter = w * h
            iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)

            inds = np.where(iou <= iou_threshold)[0]
            order = order[inds + 1]

        return keep


# ============================================================
# æ¨¡å‹ç®¡ç†å™¨
# ============================================================
class ModelManager:
    def __init__(self, model_dir: str):
        self.model_dir = model_dir
        self.models: Dict[int, Any] = {}
        self._scan_models()

    def _scan_models(self):
        if not os.path.exists(self.model_dir):
            print(f"[è­¦å‘Š] æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.model_dir}")
            return

        for filename in os.listdir(self.model_dir):
            if not filename.endswith('.onnx'):
                continue

            filepath = os.path.join(self.model_dir, filename)
            base_name = filename.replace('.onnx', '')
            base_name = base_name.replace('_720', '').replace('_bs1', '')

            try:
                algo_id = int(base_name)
            except ValueError:
                continue

            if '_720' in filename and algo_id in self.models:
                pass
            elif algo_id in self.models:
                continue

            try:
                model_type = MODEL_TYPES.get(algo_id, "yolov5")
                if model_type == "change_detection":
                    self.models[algo_id] = ONNXChangeDetector(filepath, algo_id)
                else:
                    self.models[algo_id] = ONNXYOLODetector(filepath, algo_id)
            except Exception as e:
                print(f"[é”™è¯¯] åŠ è½½æ¨¡å‹å¤±è´¥: {filename}, {e}")

        print(f"[æ¨¡å‹ç®¡ç†å™¨] åŠ è½½äº† {len(self.models)} ä¸ªæ¨¡å‹")

    def get_detector(self, algo_id: int):
        return self.models.get(algo_id)

    def is_change_detection(self, algo_id: int) -> bool:
        return MODEL_TYPES.get(algo_id) == "change_detection"

    def get_available_algos(self) -> List[Dict]:
        algos = []
        for algo_id in sorted(self.models.keys()):
            config = ALGO_CONFIG.get(algo_id, {})
            algos.append({
                "id": algo_id,
                "name": config.get("name", f"ç®—æ³•{algo_id}"),
                "classes": config.get("classes", {}),
                "type": "change_detection" if self.is_change_detection(algo_id) else "detection"
            })
        return algos


# ============================================================
# å›¾ç‰‡æ–‡ä»¶å¤¹ç®¡ç†å™¨
# ============================================================
class ImageFolderManager:
    SUPPORTED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}

    def __init__(self, image_dir: str):
        self.image_dir = image_dir

    def get_folders(self) -> List[Dict]:
        if not os.path.exists(self.image_dir):
            return []

        folders = []

        root_image_count = sum(1 for f in os.listdir(self.image_dir)
                               if os.path.isfile(os.path.join(self.image_dir, f)) and
                               Path(f).suffix.lower() in self.SUPPORTED_EXTENSIONS)
        if root_image_count > 0:
            folders.append({
                "name": "ğŸ“· å½“å‰ç›®å½•",
                "path": "__ROOT__",
                "image_count": root_image_count
            })

        for name in sorted(os.listdir(self.image_dir)):
            folder_path = os.path.join(self.image_dir, name)
            if os.path.isdir(folder_path):
                image_count = sum(1 for f in os.listdir(folder_path)
                                  if Path(f).suffix.lower() in self.SUPPORTED_EXTENSIONS)
                if image_count > 0:
                    folders.append({
                        "name": name,
                        "path": name,
                        "image_count": image_count
                    })

        return folders

    def get_images(self, folder_name: str) -> List[Dict]:
        if folder_name == "__ROOT__":
            folder_path = self.image_dir
        else:
            folder_path = os.path.join(self.image_dir, folder_name)

        if not os.path.exists(folder_path):
            return []

        images = []
        for filename in sorted(os.listdir(folder_path)):
            filepath = os.path.join(folder_path, filename)
            if os.path.isfile(filepath) and Path(filename).suffix.lower() in self.SUPPORTED_EXTENSIONS:
                size = os.path.getsize(filepath)
                if folder_name == "__ROOT__":
                    rel_path = filename
                else:
                    rel_path = f"{folder_name}/{filename}"
                images.append({
                    "name": filename,
                    "path": rel_path,
                    "size": size,
                    "size_str": self._format_size(size)
                })

        return images

    def get_all_images(self) -> List[Dict]:
        """è·å–ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡ï¼ˆä¸é€’å½’ï¼‰"""
        if not os.path.exists(self.image_dir):
            return []

        images = []
        for filename in sorted(os.listdir(self.image_dir)):
            filepath = os.path.join(self.image_dir, filename)
            if os.path.isfile(filepath) and Path(filename).suffix.lower() in self.SUPPORTED_EXTENSIONS:
                size = os.path.getsize(filepath)
                images.append({
                    "name": filename,
                    "path": filename,
                    "full_path": filepath,
                    "size": size,
                    "size_str": self._format_size(size)
                })

        return images

    def get_image_path(self, relative_path: str) -> Optional[str]:
        full_path = os.path.join(self.image_dir, relative_path)
        if os.path.exists(full_path):
            return full_path
        return None

    @staticmethod
    def _format_size(size: int) -> str:
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} TB"


# ============================================================
# ç»˜å›¾å·¥å…·
# ============================================================
def draw_detections(image: np.ndarray, detections: List[Dict], algo_id: int = None) -> np.ndarray:
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœï¼ˆæ”¯æŒä¸­æ–‡ï¼‰"""
    from PIL import Image, ImageDraw, ImageFont

    result = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(result)
    draw = ImageDraw.Draw(pil_image)

    font = None
    font_size = 20
    font_paths = [
        "C:/Windows/Fonts/msyh.ttc",
        "C:/Windows/Fonts/simsun.ttc",
        "C:/Windows/Fonts/simhei.ttf",
        "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",
        "/System/Library/Fonts/PingFang.ttc",
    ]
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                font = ImageFont.truetype(font_path, font_size)
                break
            except:
                continue

    if font is None:
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()

    colors = [
        (0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (128, 255, 0), (255, 128, 0),
        (128, 0, 255), (0, 128, 255), (255, 0, 128), (0, 255, 128),
    ]

    for det in detections:
        bbox = det["bbox"]
        x1, y1, x2, y2 = map(int, bbox)
        class_id = det.get("class_id", 0)
        class_name = det.get("class_name", f"class_{class_id}")
        confidence = det.get("confidence", 1.0)

        color = colors[class_id % len(colors)]

        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)

        label = f"{class_name} {confidence:.2f}"

        try:
            bbox_text = draw.textbbox((0, 0), label, font=font)
            text_w = bbox_text[2] - bbox_text[0]
            text_h = bbox_text[3] - bbox_text[1]
        except:
            text_w, text_h = len(label) * 10, 20

        label_y = max(y1 - text_h - 8, 0)
        draw.rectangle([x1, label_y, x1 + text_w + 10, label_y + text_h + 6], fill=color)
        draw.text((x1 + 5, label_y + 2), label, fill=(255, 255, 255), font=font)

    result = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    return result


def draw_ground_truth(image: np.ndarray, labels: List[Dict], algo_id: int = None) -> np.ndarray:
    """æ ¹æ®çœŸå®æ ‡ç­¾ç»˜åˆ¶æ¡†"""
    from PIL import Image, ImageDraw, ImageFont

    result = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(result)
    draw = ImageDraw.Draw(pil_image)

    font = None
    font_size = 20
    font_paths = [
        "C:/Windows/Fonts/msyh.ttc",
        "C:/Windows/Fonts/simsun.ttc",
        "C:/Windows/Fonts/simhei.ttf",
        "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",
        "/System/Library/Fonts/PingFang.ttc",
    ]
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                font = ImageFont.truetype(font_path, font_size)
                break
            except:
                continue

    if font is None:
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()

    # ä½¿ç”¨ä¸åŒçš„é¢œè‰²æ–¹æ¡ˆï¼ˆè“è‰²ç³»ï¼‰æ¥åŒºåˆ†çœŸå®æ ‡ç­¾
    colors = [
        (0, 128, 255), (0, 200, 255), (50, 150, 255), (100, 100, 255),
        (150, 50, 255), (200, 0, 200), (255, 100, 150), (100, 255, 200),
    ]

    algo_classes = ALGO_CONFIG.get(algo_id, {}).get("classes", {}) if algo_id else {}

    for label in labels:
        bbox = label["bbox"]
        x1, y1, x2, y2 = map(int, bbox)
        class_id = label.get("class_id", 0)
        class_name = algo_classes.get(class_id, f"class_{class_id}")

        color = colors[class_id % len(colors)]

        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)

        label_text = f"GT: {class_name}"

        try:
            bbox_text = draw.textbbox((0, 0), label_text, font=font)
            text_w = bbox_text[2] - bbox_text[0]
            text_h = bbox_text[3] - bbox_text[1]
        except:
            text_w, text_h = len(label_text) * 10, 20

        label_y = max(y1 - text_h - 8, 0)
        draw.rectangle([x1, label_y, x1 + text_w + 10, label_y + text_h + 6], fill=color)
        draw.text((x1 + 5, label_y + 2), label_text, fill=(255, 255, 255), font=font)

    result = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    return result


# ============================================================
# Flask åº”ç”¨
# ============================================================
app = Flask(__name__, static_folder=None)
CORS(app)

model_manager: ModelManager = None
image_manager: ImageFolderManager = None

# å­˜å‚¨æ‰¹é‡æ£€æµ‹ç»“æœ
batch_results = {}


@app.route('/')
def index():
    return send_from_directory('.', 'onnx_demo.html')


@app.route('/api/config', methods=['POST', 'GET'])
def api_config():
    global model_manager, image_manager

    if request.method == 'GET':
        return jsonify({
            "code": 200,
            "data": {
                "model_dir": model_manager.model_dir if model_manager else MODEL_DIR,
                "image_dir": image_manager.image_dir if image_manager else IMAGE_DIR
            }
        })

    try:
        data = request.get_json()
        new_model_dir = data.get('model_dir')
        new_image_dir = data.get('image_dir')

        if new_model_dir:
            if os.path.exists(new_model_dir):
                model_manager = ModelManager(new_model_dir)
                print(f"[é…ç½®] æ¨¡å‹ç›®å½•å·²æ›´æ–°: {new_model_dir}")
            else:
                return jsonify({"code": 400, "message": f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {new_model_dir}"})

        if new_image_dir:
            if os.path.exists(new_image_dir):
                image_manager = ImageFolderManager(new_image_dir)
                print(f"[é…ç½®] å›¾ç‰‡ç›®å½•å·²æ›´æ–°: {new_image_dir}")
            else:
                return jsonify({"code": 400, "message": f"å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {new_image_dir}"})

        return jsonify({
            "code": 200,
            "message": "é…ç½®å·²æ›´æ–°",
            "data": {
                "model_dir": model_manager.model_dir if model_manager else new_model_dir,
                "image_dir": image_manager.image_dir if image_manager else new_image_dir
            }
        })
    except Exception as e:
        return jsonify({"code": 500, "message": str(e)})


@app.route('/api/algorithms')
def get_algorithms():
    return jsonify({
        "code": 200,
        "data": model_manager.get_available_algos()
    })


@app.route('/api/folders')
def get_folders():
    return jsonify({
        "code": 200,
        "data": image_manager.get_folders()
    })


@app.route('/api/images/<path:folder_name>')
def get_images(folder_name: str):
    return jsonify({
        "code": 200,
        "data": image_manager.get_images(folder_name)
    })


@app.route('/api/image/<path:image_path>')
def get_image(image_path: str):
    full_path = image_manager.get_image_path(image_path)
    if full_path:
        return send_file(full_path)
    return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404


@app.route('/api/thumb/<path:image_path>')
def get_thumbnail(image_path: str):
    full_path = image_manager.get_image_path(image_path)
    if not full_path:
        return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404

    try:
        image = cv2.imdecode(np.fromfile(full_path, dtype=np.uint8), cv2.IMREAD_COLOR)
        if image is None:
            return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡"}), 400

        h, w = image.shape[:2]
        max_size = 100
        if w > h:
            new_w = max_size
            new_h = int(h * max_size / w)
        else:
            new_h = max_size
            new_w = int(w * max_size / h)

        thumb = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
        _, buffer = cv2.imencode('.jpg', thumb, [cv2.IMWRITE_JPEG_QUALITY, 70])

        return send_file(BytesIO(buffer.tobytes()), mimetype='image/jpeg')
    except Exception as e:
        return jsonify({"code": 500, "message": str(e)}), 500


@app.route('/api/detect', methods=['POST'])
def detect():
    """æ‰§è¡Œå•å¼ å›¾ç‰‡ç›®æ ‡æ£€æµ‹"""
    data = request.json

    algo_id = data.get('algorithm_id')
    image_path = data.get('image_path')
    conf_threshold = data.get('conf_threshold', DEFAULT_CONF)
    iou_threshold = data.get('iou_threshold', DEFAULT_IOU)

    if not algo_id:
        return jsonify({"code": 400, "message": "ç¼ºå°‘ algorithm_id"}), 400

    if not image_path:
        return jsonify({"code": 400, "message": "ç¼ºå°‘ image_path"}), 400

    detector = model_manager.get_detector(algo_id)
    if not detector:
        return jsonify({"code": 404, "message": f"ç®—æ³• {algo_id} ä¸å­˜åœ¨"}), 404

    full_path = image_manager.get_image_path(image_path)
    if not full_path:
        return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404

    try:
        image = cv2.imdecode(np.fromfile(full_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    except Exception as e:
        return jsonify({"code": 400, "message": f"è¯»å–å›¾ç‰‡å¤±è´¥: {e}"}), 400

    if image is None:
        return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡"}), 400

    img_h, img_w = image.shape[:2]

    t0 = time.time()
    try:
        detections = detector.detect(image, conf_threshold, iou_threshold)
    except Exception as e:
        return jsonify({"code": 500, "message": f"æ£€æµ‹å¤±è´¥: {e}"}), 500

    detect_time = time.time() - t0

    result_image = draw_detections(image, detections, algo_id)
    _, buffer = cv2.imencode('.jpg', result_image, [cv2.IMWRITE_JPEG_QUALITY, 90])
    result_b64 = base64.b64encode(buffer).decode('utf-8')

    algo_config = ALGO_CONFIG.get(algo_id, {})

    return jsonify({
        "code": 200,
        "data": {
            "algorithm_id": algo_id,
            "algorithm_name": algo_config.get("name", f"ç®—æ³•{algo_id}"),
            "image_width": img_w,
            "image_height": img_h,
            "detections": detections,
            "total_count": len(detections),
            "detect_time": round(detect_time, 3),
            "result_image": f"data:image/jpeg;base64,{result_b64}"
        }
    })


@app.route('/api/detect_change', methods=['POST'])
def detect_change():
    """æ‰§è¡Œå˜åŒ–æ£€æµ‹ï¼ˆéœ€è¦ä¸¤å¼ å›¾ç‰‡ï¼‰"""
    data = request.json

    algo_id = data.get('algorithm_id', 13)
    image_path1 = data.get('image_path1')
    image_path2 = data.get('image_path2')

    if not image_path1 or not image_path2:
        return jsonify({"code": 400, "message": "éœ€è¦æä¾›ä¸¤å¼ å›¾ç‰‡è·¯å¾„"}), 400

    detector = model_manager.get_detector(algo_id)
    if not detector:
        return jsonify({"code": 404, "message": f"ç®—æ³• {algo_id} ä¸å­˜åœ¨"}), 404

    if not model_manager.is_change_detection(algo_id):
        return jsonify({"code": 400, "message": f"ç®—æ³• {algo_id} ä¸æ˜¯å˜åŒ–æ£€æµ‹æ¨¡å‹"}), 400

    full_path1 = image_manager.get_image_path(image_path1)
    full_path2 = image_manager.get_image_path(image_path2)

    if not full_path1 or not full_path2:
        return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404

    try:
        image1_orig = cv2.imdecode(np.fromfile(full_path1, dtype=np.uint8), cv2.IMREAD_COLOR)
        image2_orig = cv2.imdecode(np.fromfile(full_path2, dtype=np.uint8), cv2.IMREAD_COLOR)
    except Exception as e:
        return jsonify({"code": 400, "message": f"è¯»å–å›¾ç‰‡å¤±è´¥: {e}"}), 400

    if image1_orig is None or image2_orig is None:
        return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡"}), 400

    input_size = 256
    image1 = cv2.resize(image1_orig, (input_size, input_size))
    image2 = cv2.resize(image2_orig, (input_size, input_size))

    try:
        mask_color, change_ratio, detect_time = detector.detect(image1, image2)
    except Exception as e:
        return jsonify({"code": 500, "message": f"æ£€æµ‹å¤±è´¥: {e}"}), 500

    overlay = image2.copy()
    overlay[mask_color[:, :, 2] > 0] = [0, 0, 255]
    blended = cv2.addWeighted(image2, 0.7, overlay, 0.3, 0)

    _, buffer_mask = cv2.imencode('.jpg', mask_color, [cv2.IMWRITE_JPEG_QUALITY, 90])
    _, buffer_blend = cv2.imencode('.jpg', blended, [cv2.IMWRITE_JPEG_QUALITY, 90])

    mask_b64 = base64.b64encode(buffer_mask).decode('utf-8')
    blend_b64 = base64.b64encode(buffer_blend).decode('utf-8')

    algo_config = ALGO_CONFIG.get(algo_id, {})

    return jsonify({
        "code": 200,
        "data": {
            "algorithm_id": algo_id,
            "algorithm_name": algo_config.get("name", "å˜åŒ–æ£€æµ‹"),
            "image_width": input_size,
            "image_height": input_size,
            "change_ratio": round(change_ratio * 100, 2),
            "detect_time": round(detect_time, 3),
            "mask_image": f"data:image/jpeg;base64,{mask_b64}",
            "result_image": f"data:image/jpeg;base64,{blend_b64}"
        }
    })


@app.route('/api/batch_detect', methods=['POST'])
def batch_detect():
    """æ‰¹é‡æ£€æµ‹æ•´ä¸ªç›®å½•ä¸‹çš„å›¾ç‰‡"""
    global batch_results
    
    data = request.json
    
    algo_id = data.get('algorithm_id')
    image_dir = data.get('image_dir')
    label_dir = data.get('label_dir')
    output_dir = data.get('output_dir')
    conf_threshold = data.get('conf_threshold', DEFAULT_CONF)
    iou_threshold = data.get('iou_threshold', DEFAULT_IOU)
    
    if not algo_id:
        return jsonify({"code": 400, "message": "ç¼ºå°‘ algorithm_id"}), 400
    
    if not image_dir or not label_dir or not output_dir:
        return jsonify({"code": 400, "message": "ç¼ºå°‘ç›®å½•å‚æ•°"}), 400
    
    # éªŒè¯ç›®å½•
    if not os.path.exists(image_dir):
        return jsonify({"code": 400, "message": f"å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {image_dir}"}), 400
    
    if not os.path.exists(label_dir):
        return jsonify({"code": 400, "message": f"æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {label_dir}"}), 400
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–æ£€æµ‹å™¨
    detector = model_manager.get_detector(algo_id)
    if not detector:
        return jsonify({"code": 404, "message": f"ç®—æ³• {algo_id} ä¸å­˜åœ¨"}), 404
    
    # è·å–æ‰€æœ‰å›¾ç‰‡
    temp_manager = ImageFolderManager(image_dir)
    images = temp_manager.get_all_images()
    
    if len(images) == 0:
        return jsonify({"code": 400, "message": "ç›®å½•ä¸‹æ²¡æœ‰å›¾ç‰‡"}), 400
    
    results = []
    total_images = len(images)
    
    for idx, img_info in enumerate(images):
        img_name = img_info['name']
        img_path = img_info['full_path']
        
        # è¯»å–å›¾ç‰‡
        try:
            image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if image is None:
                continue
        except Exception:
            continue
        
        img_h, img_w = image.shape[:2]
        
        # æ‰§è¡Œæ£€æµ‹
        try:
            detections = detector.detect(image, conf_threshold, iou_threshold)
        except Exception:
            continue
        
        # è·å–å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
        label_name = Path(img_name).stem + '.txt'
        label_path = os.path.join(label_dir, label_name)
        
        # è§£æçœŸå®æ ‡ç­¾
        ground_truths = parse_yolo_label(label_path, img_w, img_h)
        
        # è®¡ç®—æ­£ç¡®ç‡
        accuracy = calculate_accuracy(detections, ground_truths, iou_threshold=0.5)
        
        results.append({
            'name': img_name,
            'path': img_path,
            'accuracy': accuracy,
            'detections': detections,
            'ground_truths': ground_truths,
            'width': img_w,
            'height': img_h
        })
    
    # å­˜å‚¨ç»“æœ
    batch_results = {
        'algo_id': algo_id,
        'image_dir': image_dir,
        'label_dir': label_dir,
        'output_dir': output_dir,
        'results': results,
        'total_count': len(results)
    }
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    accuracies = [r['accuracy'] for r in results]
    avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0
    high_acc_count = sum(1 for a in accuracies if a >= 0.95)
    
    return jsonify({
        "code": 200,
        "data": {
            "total_images": len(results),
            "avg_accuracy": round(avg_accuracy * 100, 2),
            "high_accuracy_count": high_acc_count,
            "results": [
                {
                    'name': r['name'],
                    'accuracy': round(r['accuracy'] * 100, 2),
                    'detection_count': len(r['detections']),
                    'gt_count': len(r['ground_truths'])
                }
                for r in results
            ]
        }
    })


@app.route('/api/save_results', methods=['POST'])
def save_results():
    """ä¿å­˜æ£€æµ‹ç»“æœåˆ°è¾“å‡ºç›®å½•"""
    global batch_results
    
    if not batch_results or 'results' not in batch_results:
        return jsonify({"code": 400, "message": "æ²¡æœ‰å¯ä¿å­˜çš„æ‰¹é‡æ£€æµ‹ç»“æœ"}), 400
    
    data = request.json
    min_accuracy = data.get('min_accuracy', 0.87)
    target_count = data.get('target_count', 100)
    
    results = batch_results['results']
    algo_id = batch_results['algo_id']
    output_dir = batch_results['output_dir']
    
    # ç­›é€‰å›¾ç‰‡
    high_acc_95 = [r for r in results if r['accuracy'] >= 0.95]
    
    if len(high_acc_95) >= target_count:
        # ä»90%-100%åŒºé—´éšæœºé€‰æ‹©
        range_90_100 = [r for r in results if 0.90 <= r['accuracy'] <= 1.0]
        if len(range_90_100) >= target_count:
            selected = random.sample(range_90_100, target_count)
        else:
            selected = range_90_100
    else:
        # é€‰æ‹©æ­£ç¡®ç‡æœ€é«˜çš„100å¼ 
        sorted_results = sorted(results, key=lambda x: x['accuracy'], reverse=True)
        selected = sorted_results[:target_count]
    
    # å°è¯•ä¿è¯æ€»æ­£ç¡®ç‡ä¸ä½äº87%
    selected_acc = [r['accuracy'] for r in selected]
    current_avg = sum(selected_acc) / len(selected_acc) if selected_acc else 0
    
    if current_avg < min_accuracy:
        # é‡æ–°ç­›é€‰ï¼Œä¼˜å…ˆé€‰æ‹©é«˜æ­£ç¡®ç‡çš„
        sorted_results = sorted(results, key=lambda x: x['accuracy'], reverse=True)
        selected = []
        for r in sorted_results:
            selected.append(r)
            if len(selected) >= target_count:
                break
            current_avg = sum(s['accuracy'] for s in selected) / len(selected)
            if len(selected) >= target_count and current_avg >= min_accuracy:
                break
    
    # åˆ›å»ºè¾“å‡ºå­ç›®å½•
    subdirs = ['images', 'detect_images', 'real_images', 'detect_labels', 'real_labels']
    for subdir in subdirs:
        os.makedirs(os.path.join(output_dir, subdir), exist_ok=True)
    
    # ä¿å­˜æ–‡ä»¶
    saved_count = 0
    detector = model_manager.get_detector(algo_id)
    
    for result in selected:
        img_name = result['name']
        img_path = result['path']
        base_name = Path(img_name).stem
        
        try:
            # è¯»å–åŸå›¾
            image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if image is None:
                continue
            
            img_h, img_w = image.shape[:2]
            
            # 1. ä¿å­˜åŸå›¾
            orig_out_path = os.path.join(output_dir, 'images', img_name)
            cv2.imencode(Path(img_name).suffix, image)[1].tofile(orig_out_path)
            
            # 2. ä¿å­˜æ£€æµ‹åçš„å›¾åƒ
            detect_image = draw_detections(image.copy(), result['detections'], algo_id)
            detect_out_path = os.path.join(output_dir, 'detect_images', img_name)
            cv2.imencode(Path(img_name).suffix, detect_image)[1].tofile(detect_out_path)
            
            # 3. ä¿å­˜çœŸå®æ ‡ç­¾å›¾åƒ
            real_image = draw_ground_truth(image.copy(), result['ground_truths'], algo_id)
            real_out_path = os.path.join(output_dir, 'real_images', img_name)
            cv2.imencode(Path(img_name).suffix, real_image)[1].tofile(real_out_path)
            
            # 4. ä¿å­˜æ£€æµ‹æ ‡ç­¾txt
            detect_label = detections_to_yolo_format(result['detections'], img_w, img_h)
            detect_label_path = os.path.join(output_dir, 'detect_labels', f'{base_name}.txt')
            with open(detect_label_path, 'w', encoding='utf-8') as f:
                f.write(detect_label)
            
            # 5. å¤åˆ¶çœŸå®æ ‡ç­¾txt
            real_label_src = os.path.join(batch_results['label_dir'], f'{base_name}.txt')
            real_label_dst = os.path.join(output_dir, 'real_labels', f'{base_name}.txt')
            if os.path.exists(real_label_src):
                shutil.copy2(real_label_src, real_label_dst)
            
            saved_count += 1
            
        except Exception as e:
            print(f"[è­¦å‘Š] ä¿å­˜æ–‡ä»¶å¤±è´¥: {img_name}, {e}")
            continue
    
    # è®¡ç®—ä¿å­˜çš„å›¾ç‰‡çš„æ€»æ­£ç¡®ç‡
    saved_accuracies = [r['accuracy'] for r in selected[:saved_count]]
    total_accuracy = sum(saved_accuracies) / len(saved_accuracies) if saved_accuracies else 0
    
    # æ›´æ–°image_manageræŒ‡å‘æ–°çš„imagesç›®å½•
    global image_manager
    new_image_dir = os.path.join(output_dir, 'images')
    image_manager = ImageFolderManager(new_image_dir)
    
    return jsonify({
        "code": 200,
        "data": {
            "saved_count": saved_count,
            "total_accuracy": round(total_accuracy * 100, 2),
            "output_dir": output_dir,
            "new_image_dir": new_image_dir
        }
    })


@app.route('/api/get_comparison', methods=['POST'])
def get_comparison():
    """è·å–å•å¼ å›¾ç‰‡çš„å¯¹æ¯”è§†å›¾ï¼ˆåŸå›¾ã€æ£€æµ‹å›¾ã€çœŸå®æ ‡ç­¾å›¾ï¼‰"""
    global batch_results
    
    data = request.json
    image_name = data.get('image_name')
    
    if not image_name:
        return jsonify({"code": 400, "message": "ç¼ºå°‘å›¾ç‰‡åç§°"}), 400
    
    # é¦–å…ˆæ£€æŸ¥batch_resultsä¸­æ˜¯å¦æœ‰è¯¥å›¾ç‰‡
    result = None
    if batch_results and 'results' in batch_results:
        for r in batch_results['results']:
            if r['name'] == image_name:
                result = r
                break
    
    # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„ç»“æœï¼Œä»å½“å‰ç›®å½•è·å–
    if not result:
        # ä»å½“å‰image_managerçš„ç›®å½•è¯»å–
        img_path = image_manager.get_image_path(image_name)
        if not img_path:
            return jsonify({"code": 404, "message": "å›¾ç‰‡ä¸å­˜åœ¨"}), 404
        
        try:
            image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if image is None:
                return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡"}), 400
        except Exception as e:
            return jsonify({"code": 400, "message": f"è¯»å–å›¾ç‰‡å¤±è´¥: {e}"}), 400
        
        img_h, img_w = image.shape[:2]
        
        # å°è¯•è·å–æ£€æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼ˆä»outputç›®å½•ç»“æ„ï¼‰
        output_dir = os.path.dirname(image_manager.image_dir)
        
        # è¯»å–æ£€æµ‹å›¾
        detect_img_path = os.path.join(output_dir, 'detect_images', image_name)
        real_img_path = os.path.join(output_dir, 'real_images', image_name)
        detect_label_path = os.path.join(output_dir, 'detect_labels', Path(image_name).stem + '.txt')
        real_label_path = os.path.join(output_dir, 'real_labels', Path(image_name).stem + '.txt')
        
        # ç¼–ç åŸå›¾
        _, orig_buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 90])
        orig_b64 = base64.b64encode(orig_buffer).decode('utf-8')
        
        # ç¼–ç æ£€æµ‹å›¾
        detect_b64 = None
        if os.path.exists(detect_img_path):
            detect_img = cv2.imdecode(np.fromfile(detect_img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if detect_img is not None:
                _, detect_buffer = cv2.imencode('.jpg', detect_img, [cv2.IMWRITE_JPEG_QUALITY, 90])
                detect_b64 = base64.b64encode(detect_buffer).decode('utf-8')
        
        # ç¼–ç çœŸå®æ ‡ç­¾å›¾
        real_b64 = None
        if os.path.exists(real_img_path):
            real_img = cv2.imdecode(np.fromfile(real_img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if real_img is not None:
                _, real_buffer = cv2.imencode('.jpg', real_img, [cv2.IMWRITE_JPEG_QUALITY, 90])
                real_b64 = base64.b64encode(real_buffer).decode('utf-8')
        
        # è§£ææ ‡ç­¾è®¡ç®—æ­£ç¡®ç‡
        detections = []
        ground_truths = []
        
        if os.path.exists(detect_label_path):
            detections = parse_yolo_label(detect_label_path, img_w, img_h)
        
        if os.path.exists(real_label_path):
            ground_truths = parse_yolo_label(real_label_path, img_w, img_h)
        
        accuracy = calculate_accuracy(detections, ground_truths, iou_threshold=0.5)
        
        return jsonify({
            "code": 200,
            "data": {
                "name": image_name,
                "accuracy": round(accuracy * 100, 2),
                "detection_count": len(detections),
                "gt_count": len(ground_truths),
                "original_image": f"data:image/jpeg;base64,{orig_b64}",
                "detect_image": f"data:image/jpeg;base64,{detect_b64}" if detect_b64 else None,
                "real_image": f"data:image/jpeg;base64,{real_b64}" if real_b64 else None
            }
        })
    
    # æœ‰ç¼“å­˜çš„ç»“æœ
    img_path = result['path']
    
    try:
        image = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
        if image is None:
            return jsonify({"code": 400, "message": "æ— æ³•è¯»å–å›¾ç‰‡"}), 400
    except Exception as e:
        return jsonify({"code": 400, "message": f"è¯»å–å›¾ç‰‡å¤±è´¥: {e}"}), 400
    
    algo_id = batch_results.get('algo_id')
    
    # ç¼–ç åŸå›¾
    _, orig_buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 90])
    orig_b64 = base64.b64encode(orig_buffer).decode('utf-8')
    
    # ç»˜åˆ¶å¹¶ç¼–ç æ£€æµ‹å›¾
    detect_image = draw_detections(image.copy(), result['detections'], algo_id)
    _, detect_buffer = cv2.imencode('.jpg', detect_image, [cv2.IMWRITE_JPEG_QUALITY, 90])
    detect_b64 = base64.b64encode(detect_buffer).decode('utf-8')
    
    # ç»˜åˆ¶å¹¶ç¼–ç çœŸå®æ ‡ç­¾å›¾
    real_image = draw_ground_truth(image.copy(), result['ground_truths'], algo_id)
    _, real_buffer = cv2.imencode('.jpg', real_image, [cv2.IMWRITE_JPEG_QUALITY, 90])
    real_b64 = base64.b64encode(real_buffer).decode('utf-8')
    
    return jsonify({
        "code": 200,
        "data": {
            "name": image_name,
            "accuracy": round(result['accuracy'] * 100, 2),
            "detection_count": len(result['detections']),
            "gt_count": len(result['ground_truths']),
            "original_image": f"data:image/jpeg;base64,{orig_b64}",
            "detect_image": f"data:image/jpeg;base64,{detect_b64}",
            "real_image": f"data:image/jpeg;base64,{real_b64}"
        }
    })


@app.route('/api/batch_results')
def get_batch_results():
    """è·å–æ‰¹é‡æ£€æµ‹ç»“æœæ‘˜è¦"""
    global batch_results
    
    if not batch_results or 'results' not in batch_results:
        return jsonify({"code": 404, "message": "æ²¡æœ‰æ‰¹é‡æ£€æµ‹ç»“æœ"})
    
    results = batch_results['results']
    accuracies = [r['accuracy'] for r in results]
    
    return jsonify({
        "code": 200,
        "data": {
            "total_count": len(results),
            "avg_accuracy": round(sum(accuracies) / len(accuracies) * 100, 2) if accuracies else 0,
            "high_95_count": sum(1 for a in accuracies if a >= 0.95),
            "high_90_count": sum(1 for a in accuracies if a >= 0.90),
            "results": [
                {
                    'name': r['name'],
                    'accuracy': round(r['accuracy'] * 100, 2)
                }
                for r in sorted(results, key=lambda x: x['accuracy'], reverse=True)
            ]
        }
    })


def main():
    global model_manager, image_manager

    print("=" * 60)
    print("ONNX å¯è§†åŒ–æ¼”ç¤ºæœåŠ¡ (å¢å¼ºç‰ˆ)")
    print("=" * 60)
    print(f"æ¨¡å‹ç›®å½•: {MODEL_DIR}")
    print(f"å›¾ç‰‡ç›®å½•: {IMAGE_DIR}")
    print(f"æœåŠ¡åœ°å€: http://{SERVER_HOST}:{SERVER_PORT}")
    print("=" * 60)

    if not os.path.exists(MODEL_DIR):
        print(f"\n[è­¦å‘Š] æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: {MODEL_DIR}")
        os.makedirs(MODEL_DIR, exist_ok=True)

    if not os.path.exists(IMAGE_DIR):
        print(f"\n[è­¦å‘Š] å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: {IMAGE_DIR}")
        os.makedirs(IMAGE_DIR, exist_ok=True)

    model_manager = ModelManager(MODEL_DIR)
    image_manager = ImageFolderManager(IMAGE_DIR)

    print(f"\nğŸš€ æœåŠ¡å·²å¯åŠ¨: http://localhost:{SERVER_PORT}")
    print(f"   æµè§ˆå™¨è®¿é—®ä¸Šè¿°åœ°å€å³å¯ä½¿ç”¨\n")
    app.run(host=SERVER_HOST, port=SERVER_PORT, debug=False, threaded=True)


if __name__ == '__main__':
    main()
